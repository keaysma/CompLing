{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sytax Tree Builder\n",
    "### This is an notebook to research all properties of syntax trees, including:\n",
    "- Finding association rules\n",
    "\n",
    "- Filling in the blank on missing word classes\n",
    "\n",
    "- Building trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import math\n",
    "import requests\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "from PyDictionary import PyDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-X-Bar Theory Implementation\n",
    "## This was made for the simpler units of LING486"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'The big man from n loving bagels with n'\n",
    "#'The cat killed the dirty dog in the house because he threw nasty bread by the fire'\n",
    "#\"in the smelly and wholesome and brilliant and bubbly couch\"\n",
    "#\"the brilliant and bubbly and whimsical ball\"\n",
    "p = nltk.parse.api.ParserI\n",
    "_d=PyDictionary()\n",
    "\n",
    "#Array forces ordering\n",
    "syntaxRulesReverse = [\n",
    "    ['(adjconj)+adj', 'adj'], \n",
    "    ['(advP)*adj', 'ajP'], \n",
    "    ['(advP)?adv', 'avP'], \n",
    "    ['PnP', 'pP'],\n",
    "    ['(D)?(ajP)*N(pP)*(CP)?', 'nP'], \n",
    "    ['V(nP)+(pP)*', 'vP'], \n",
    "    ['(Nconj)+N', 'N'],\n",
    "    ['(nPconj)+nP', 'nP'],\n",
    "    ['nPvP', 'tP'],\n",
    "    ['(tPconj)+tP', 'tP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/mkeays/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Word given is not a valid English Word\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'XadjNXNVNXN'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x = x.split()\n",
    "_xd = \"\"\n",
    "for token in _x:\n",
    "    _xd += getClass(token)\n",
    "_xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......XadjNXNVNXN\n",
      "|\n",
      "XajPNXNVNXN\n",
      "|\n",
      "XnPXNVNXN\n",
      "|\n",
      "XnPXnPVNXN\n",
      "|\n",
      "XnPXnPVnPXN\n",
      "|\n",
      "XnPXnPVnPXnP\n",
      "|\n",
      "XnPXnPvPXnP\n",
      "|\n",
      "XnPXtPXnP\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "tree = [_xd]\n",
    "diagram = []\n",
    "while needsParsing(tree[-1]):\n",
    "    level = \"\"\n",
    "    dlvl = []\n",
    "    for rule in syntaxRulesReverse:\n",
    "        m = re.search(rule[0], tree[-1])\n",
    "        if m:\n",
    "            level = tree[-1][0:m.start()] + rule[1] + tree[-1][m.end():]\n",
    "            tree += [level]\n",
    "            dlvl += [rule[1], tree[-1][m.start():m.end()], m.start(), m.end()]\n",
    "            diagram += [dlvl]\n",
    "            break\n",
    "    if level == \"\":\n",
    "        break\n",
    "    print('.', end='')\n",
    "[print(_, end='\\n|\\n') for _ in tree];None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bf522b9da5be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0m_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyntaxRulesReverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msyntaxRulesReverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'start'"
     ]
    }
   ],
   "source": [
    "_search = re.search(tree[-2], syntaxRulesReverse[-1][0])\n",
    "tree[-2][0:_search.start()] + syntaxRulesReverse[-1][1] + tree[-2][_search.end():]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def needsParsing(x):\n",
    "    if x != 'nP' and x != 'tP' and x != 'vP' and x != 'CP' and x!= 'pP':\n",
    "        return True\n",
    "    return False\n",
    "def getClass(x):\n",
    "    wC = 'X'\n",
    "    #Meaning -- regular\n",
    "    word = _d.meaning(x)\n",
    "    if word is not None:\n",
    "        wC = list(word.keys())[0]\n",
    "    \n",
    "    #Meaning -- google\n",
    "    word = _d.googlemeaning(x)\n",
    "    if word is not None:\n",
    "        wC =  word.split(':')[1].split()[0]\n",
    "\n",
    "    if wC.lower() == 'noun' or wC.lower() == 'pronoun':\n",
    "        return 'N'\n",
    "    elif wC.lower() == 'verb':\n",
    "        return 'V'\n",
    "    elif wC.lower() == 'adjective':\n",
    "        return 'adj'\n",
    "    elif wC.lower() == 'adverb':\n",
    "        return 'adv'\n",
    "    elif wC.lower() == 'determiner':\n",
    "        return 'D'\n",
    "    elif wC.lower() == 'preposition':\n",
    "        return 'P'\n",
    "    elif wC.lower() == 'conjunction':\n",
    "        return 'conj'\n",
    "        \n",
    "    return wC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Bar and Array Tree Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'noun'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Getting parts of speach using wordsmyth\n",
    "word = \"chopsticks\"\n",
    "url = \"https://www.wordsmyth.net/?level=3&ent={}\".format(word)\n",
    "s = requests.Session()\n",
    "res = s.get(url, verify = False)\n",
    "soup = BeautifulSoup(res.text, 'html5lib')\n",
    "soup.findAll(\"table\", {\"class\": \"maintable\"})[0].find_all('td', {\"class\": \"data\"})[0].a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDict(d, filename):\n",
    "    sD = str(d)\n",
    "    f = open(filename, 'w')\n",
    "    f.write(sD)\n",
    "    f.close()\n",
    "    \n",
    "def loadDict(filename):\n",
    "    f = open(filename, 'r')\n",
    "    sD = f.read()\n",
    "    f.close()\n",
    "    d = ast.literal_eval(sD)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary static dict\n",
    "'''\n",
    "localBank = {'is': 'v',\n",
    "             'need' : 'v',\n",
    "             'needs' : 'v',\n",
    "             'do': 'v',\n",
    "             'does': 'v',\n",
    "             'I' : 'pn',\n",
    "             'a' : 'd',\n",
    "             'the' : 'd',\n",
    "            #homework specific - no working suplementary dict\n",
    "            'well': 'adj',\n",
    "            'plays': 'v'}\n",
    "'''\n",
    "\n",
    "localBank = loadDict('local_bank.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDict(localBank, 'local_bank.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLikelyClass(word, convert = False):\n",
    "    if word in localBank:\n",
    "        return localBank[word]\n",
    "    url = \"https://www.wordsmyth.net/?level=3&ent={}\".format(word)\n",
    "    s = requests.Session()\n",
    "    res = s.get(url, verify = False)\n",
    "    soup = BeautifulSoup(res.text, 'html5lib')\n",
    "    txt = soup.findAll(\"table\", {\"class\": \"maintable\"})[0].find_all('td', {\"class\": \"data\"})[0].a.text\n",
    "    switch = {\n",
    "        'determiner'          :        'd',\n",
    "        'noun'                :        'n',\n",
    "        'pronoun'             :        'pn',\n",
    "        'preposition'         :        'p',\n",
    "        'transitive verb'     :        'v', #vt\n",
    "        'intransitive verb'  :         'v', #vi\n",
    "        'ditransitive verb'  :         'v', #vd\n",
    "        'adjective'           :        'adj',\n",
    "        'adverb'              :        'adv',\n",
    "        'conjunction'         :        'conj',\n",
    "    }\n",
    "    if convert and txt in switch:\n",
    "        localBank[word] = switch[txt]\n",
    "        return switch[txt]\n",
    "    return txt\n",
    "\n",
    "def defineLikelyClass(word, wordClass, force=False):\n",
    "    if word not in localBank or force:\n",
    "        localBank[word] = wordClass\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "defineLikelyClass('\\'s', 'd', True)\n",
    "getLikelyClass('\\'s', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For machine gunning words into the local word bank!\n",
    "x = 'The dog is in the house'.split()\n",
    "y = 'd n v p d n'.split()\n",
    "for i in range(len(x)):\n",
    "    defineLikelyClass(x[i], y[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['d', ['The']], ['n', ['coach']], ['t', ['will']], ['v', ['be']], ['v', ['using']], ['d', ['a']], ['adj', ['new']], ['n', ['approach']]]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The coach will be using a new approach\"\n",
    "#\"The dog is in the house\"\n",
    "#\"The coach will be using a new approach\" #<-- HARD\n",
    "\n",
    "#This will build all of the possible base cases for perspective\n",
    "#based on research forensics for each given word\n",
    "def constructPerspective(sentence):\n",
    "    perspective = []\n",
    "    tokens = [[_, getLikelyClass(_.lower(), True)] for _ in sentence.split(\" \")]\n",
    "    for token in tokens:\n",
    "        perspective.append([token[1], [token[0]]])\n",
    "    return perspective\n",
    "x = constructPerspective(sentence)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determines if the given rule is at the top of a given tree\n",
    "#Strict disallows the tree from having different neighbors at the top\n",
    "def inTreeTop(tree, rule, strict = False):\n",
    "    retVal = False\n",
    "    strictVal = True\n",
    "    for topNode in tree:\n",
    "        if topNode[0] == rule:\n",
    "            retVal = True\n",
    "        else:\n",
    "            strictVal = False\n",
    "    if strict:\n",
    "        return (retVal, strictVal)\n",
    "    return retVal\n",
    "def pruneTrees(trees):\n",
    "    pruned = []\n",
    "    for tree in trees:\n",
    "        finishedVal = inTreeTop(tree, \"cP\", strict = True)\n",
    "        if finishedVal[0] and finishedVal[1]:\n",
    "            pruned.append(tree)\n",
    "    return pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging handling, small but out of the tree builder to keep things clean\n",
    "def dprint(statement, currentLevel, evalLevel):\n",
    "    if currentLevel >= evalLevel or currentLevel == -1:\n",
    "        print(statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am Michael, I love Raquel, I eat protien, etc...\n",
    "rules = {\n",
    "    \"adjP\" : [[\"adjbar\"]],\n",
    "    \"adjbar\" : [[\"adj\"], [\"advP\", \"adjbar\"]],\n",
    "    \"advP\" : [[\"advbar\"]],\n",
    "    \"advbar\" : [[\"adv\"], [\"advP\", \"advbar\"]],\n",
    "    \"nbar\": [[\"adjP\", \"nbar\"], [\"nbar\", \"pP\"], [\"n\"], [\"n\", \"pP\"], [\"pn\"]],\n",
    "    \"nP\" : [[\"nbar\"], [\"nP\", \"conj\", \"nP\"]],\n",
    "    \"dbar\" : [[\"d\", \"nP\"], [\"nP\"]],\n",
    "    \"dP\" : [[\"dP\", \"dbar\"], [\"dbar\"], [\"dP\", \"conj\", \"dP\"]],\n",
    "    \"pbar\" : [[\"p\", \"dP\"]],\n",
    "    \"pP\" : [[\"pbar\"]],\n",
    "    \"vP\" : [[\"vbar\"], [\"vP\", \"conj\", \"vP\"]],\n",
    "    \"vbar\" : [[\"vbar\", \"pP\"], [\"vbar\", \"advP\"], [\"advP\", \"vbar\"], [\"vbar\", \"dP\"], [\"v\"], [\"v\", \"pP\"], [\"v\", \"dP\"], [\"v\", \"adjP\"], [\"v\", \"vP\"]],\n",
    "    \"negbar\" : [[\"neg\", \"vP\"]],\n",
    "    \"negP\" : [[\"negbar\"]],\n",
    "    \"t\" : [[\"v\"]],\n",
    "    \"tbar\" : [[\"vP\"], [\"t\", \"vP\"], [\"t\", \"negP\"]],\n",
    "    \"tP\" : [[\"dP\", \"tbar\"], [\"tP\", \"conj\", \"tP\"]],\n",
    "    \"cbar\" : [[\"c\", \"tP\"], [\"tP\"]],\n",
    "    \"cP\" : [[\"cbar\"], [\"cP\", \"conj\", \"cP\"]]\n",
    "}\n",
    "\n",
    "#This is the big boy itself\n",
    "#The rule above define what the builder will try\n",
    "#As of right now, the builder has a few problems\n",
    "#It refuses to accept verb complements\n",
    "#It does not account for null items\n",
    "#As a result it doesn't yet generate movement\n",
    "#\n",
    "#Verboseness is for debugging purposes, it works in levels\n",
    "#0 - Print nothing, smooth, user experience\n",
    "#1 - Prints things like how many trees are being considered in any one permutation of rules\n",
    "#2 - ...\n",
    "#3 - ...\n",
    "#... - ...\n",
    "#-1 - PRINTS. EVERYTHING. Be careful what you wish for!!!\n",
    "def BuildSyntaxTree(x, maxNode = \"cP\", verbose = 0):\n",
    "    #Keep track of where matches for each rule occurs, when creating a new node,\n",
    "    #select the simplest matches first (adjbar before tbar), and the match that occurs later in the tree\n",
    "    mutating = True\n",
    "    \n",
    "    #This is temporary for now -- in the future we will have multiple perspectives, not just one!\n",
    "    perspectives = [x]\n",
    "    new_perspectives, final_perspectives = [], []\n",
    "    exhaustive_perspectives = perspectives.copy()\n",
    "    \n",
    "    #Measures tree formation\n",
    "    deltas = {}\n",
    "    while mutating:\n",
    "        new_perspectives = []\n",
    "        for inp in perspectives:\n",
    "            matches = {}\n",
    "            for rule, conditionSet in rules.items():  \n",
    "                    dprint(\"Rule exploration\", verbose, 5)\n",
    "                    for conditions in conditionSet:\n",
    "                        conditionMatch, conditionPosition = 0, 0\n",
    "                        dprint(rule + \" : \" + str(conditions), verbose, 5)\n",
    "                        dprint(\"Rule matches:\", verbose, 6)\n",
    "                        for i in range(len(inp)):\n",
    "                            node = inp[i]\n",
    "                            if node[0] == conditions[conditionMatch]:\n",
    "                                dprint(rule + \", \" + node[0], verbose, 6)\n",
    "                                if conditionMatch == 0:\n",
    "                                    conditionPosition = i\n",
    "                                conditionMatch += 1\n",
    "                                if conditionMatch == len(conditions):\n",
    "                                    dprint(\"Total match for \" + rule, verbose, 6)\n",
    "                                    if rule in matches:\n",
    "                                        matches[rule] += [(conditionPosition, conditionPosition + conditionMatch)]\n",
    "                                    else:\n",
    "                                        matches.update({rule:[(conditionPosition, conditionPosition + conditionMatch)]})\n",
    "                                    conditionMatch = 0\n",
    "                            else:\n",
    "                                conditionMatch = 0\n",
    "            dprint(\"Inputs to Matches:\\n {} -> {}\".format(inp, matches), verbose, 2)\n",
    "            \n",
    "            dprint(\"Rule matches: \", verbose, 3)\n",
    "            for matchLabel, matchSets in matches.items():\n",
    "                for matchSet in matchSets:\n",
    "                    old, new = exhaustive_perspectives.index(inp), -1\n",
    "                    \n",
    "                    dprint(\"{} :- {}\".format(matchLabel, matchSet), verbose, 3)\n",
    "                    subset = inp[matchSet[0]:matchSet[1]]\n",
    "                    new_perspective = inp[:matchSet[0]] + [[matchLabel, subset]] + inp[matchSet[1]:]\n",
    "                    \n",
    "                    if new_perspective not in exhaustive_perspectives:\n",
    "                        exhaustive_perspectives.append(new_perspective)\n",
    "                    new = exhaustive_perspectives.index(new_perspective)\n",
    "                    \n",
    "                    deltas[(old, new)] = matchLabel\n",
    "                    \n",
    "                    if new_perspective not in new_perspectives:\n",
    "                        new_perspectives.append(new_perspective)\n",
    "            dprint(\"Filling in Exaustive and Final arrays...\", verbose, 2)\n",
    "            for perspective in perspectives:\n",
    "                if perspective not in exhaustive_perspectives:\n",
    "                    dprint(\"{} -> exhaustive_perspectives, generically missing\".format(perspective), verbose, 3)\n",
    "                    exhaustive_perspectives.append(perspective)\n",
    "                if inTreeTop(perspective, maxNode, strict = True) == (True, True) and perspective not in final_perspectives:\n",
    "                    dprint(\"{} -> final_perspectives, completed tree\".format(perspective), verbose, 3)\n",
    "                    final_perspectives.append(perspective)\n",
    "        #Stops searching\n",
    "        if perspectives == new_perspectives or len(new_perspectives) == 0:\n",
    "            dprint(\"Halting, onboarding last trees\", verbose, 2)\n",
    "            for perspective in new_perspectives:\n",
    "                if perspective not in final_perspectives:\n",
    "                    dprint(\"{} -> final_perspectives\".format(perspective), verbose, 3)\n",
    "                    final_perspectives.append(perspectives)\n",
    "            mutating = False\n",
    "            dprint(\"Halted\", verbose, 1)\n",
    "            break\n",
    "        perspectives = new_perspectives.copy()\n",
    "        dprint(\"Permutations in iteration: {}\".format(len(perspectives)), verbose, 1)\n",
    "    #Returns a tuple of:\n",
    "    #Final list of highest level trees\n",
    "    #All generated trees\n",
    "    #Changes, corresponding to exhaustive indicies\n",
    "    return (final_perspectives, exhaustive_perspectives, deltas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Permutations in iteration: 7\n",
      "Permutations in iteration: 24\n",
      "Permutations in iteration: 60\n",
      "Permutations in iteration: 124\n",
      "Permutations in iteration: 221\n",
      "Permutations in iteration: 343\n",
      "Permutations in iteration: 474\n",
      "Permutations in iteration: 591\n",
      "Permutations in iteration: 671\n",
      "Permutations in iteration: 701\n",
      "Permutations in iteration: 680\n",
      "Permutations in iteration: 609\n",
      "Permutations in iteration: 507\n",
      "Permutations in iteration: 391\n",
      "Permutations in iteration: 279\n",
      "Permutations in iteration: 184\n",
      "Permutations in iteration: 112\n",
      "Permutations in iteration: 62\n",
      "Permutations in iteration: 32\n",
      "Permutations in iteration: 14\n",
      "Permutations in iteration: 2\n",
      "Halted\n"
     ]
    }
   ],
   "source": [
    "treeData = BuildSyntaxTree(constructPerspective(sentence), verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFormationChain(treeData, index):\n",
    "    if index >= len(treeData[0]):\n",
    "        return (None, None)\n",
    "    idx = treeData[1].index(treeData[0][index])\n",
    "    keychain = []\n",
    "    formationchain = '{}'.format(idx)\n",
    "    newKey = True\n",
    "    while newKey:\n",
    "        newKey = False\n",
    "        for key in treeData[2].keys():\n",
    "            if key[1] == idx:\n",
    "                idx = key[0]\n",
    "                keychain.append(key)\n",
    "                formationchain = '{}->'.format(treeData[2][key]) + formationchain\n",
    "                newKey = True\n",
    "                break\n",
    "    formationchain = '{}->'.format(idx) + formationchain\n",
    "    return (formationchain, keychain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0->adjbar->adjP->nbar->nbar->nbar->nP->nP->dbar->dbar->dP->dP->vbar->vbar->vP->vbar->vP->tbar->tP->cbar->cP->6078',\n",
       " [(6050, 6078),\n",
       "  (5992, 6050),\n",
       "  (5885, 5992),\n",
       "  (5700, 5885),\n",
       "  (5420, 5700),\n",
       "  (5023, 5420),\n",
       "  (4511, 5023),\n",
       "  (3898, 4511),\n",
       "  (3217, 3898),\n",
       "  (2516, 3217),\n",
       "  (1845, 2516),\n",
       "  (1254, 1845),\n",
       "  (780, 1254),\n",
       "  (437, 780),\n",
       "  (216, 437),\n",
       "  (92, 216),\n",
       "  (32, 92),\n",
       "  (8, 32),\n",
       "  (1, 8),\n",
       "  (0, 1)])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buildFormationChain(treeData, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTree = pruneTrees(treeData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 2\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['cP',\n",
       "  [['cbar',\n",
       "    [['tP',\n",
       "      [['dP',\n",
       "        [['dbar', [['d', ['The']], ['nP', [['nbar', [['n', ['coach']]]]]]]]]],\n",
       "       ['tbar',\n",
       "        [['t', ['will']],\n",
       "         ['vP',\n",
       "          [['vbar',\n",
       "            [['vbar', [['v', ['be']], ['vP', [['vbar', [['v', ['using']]]]]]]],\n",
       "             ['dP',\n",
       "              [['dbar',\n",
       "                [['d', ['a']],\n",
       "                 ['nP',\n",
       "                  [['nbar',\n",
       "                    [['adjP', [['adjbar', [['adj', ['new']]]]]],\n",
       "                     ['nbar', [['n', ['approach']]]]]]]]]]]]]]]]]]]]]]]]]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Trees: {}\".format(len(finalTree)))\n",
    "print(treeHeight(finalTree[0]))\n",
    "finalTree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[.CP [.$\\bar{C}$ [.TP \n",
      "\t[.DP [.$\\bar{D}$ \n",
      "\t[.D The ] \n",
      "\t[.NP [.$\\bar{N}$ [.N coach ]]]]] \n",
      "\t[.$\\bar{T}$ \n",
      "\t[.T will ] \n",
      "\t[.VP [.$\\bar{V}$ \n",
      "\t[.V be ] \n",
      "\t[.VP [.$\\bar{V}$ \n",
      "\t[.$\\bar{V}$ [.V using ]] \n",
      "\t[.DP [.$\\bar{D}$ \n",
      "\t[.D a ] \n",
      "\t[.NP [.$\\bar{N}$ \n",
      "\t[.adjP [.$\\bar{adj}$ [.adj new ]]] \n",
      "\t[.$\\bar{N}$ [.N approach ]]]]]]]]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "latexKeys = {\n",
    "    \"xbar\" : '$\\\\bar{{{}}}$'\n",
    "}\n",
    "\n",
    "def printTree(tree):\n",
    "    if type(tree) == str:\n",
    "        return tree + \" \"\n",
    "    t = tree[0]\n",
    "    if type(t) == str:\n",
    "        return t + \" \"\n",
    "    label = t[0]\n",
    "    if len(label) == 1:\n",
    "        label = label.upper()\n",
    "    ploc = label.find('P')\n",
    "    if ploc > 0:\n",
    "        if len(label[:ploc]) == 1:\n",
    "            label = label.upper()\n",
    "    barloc = label.find('bar')\n",
    "    if barloc > 0:\n",
    "        sublabel = label[:barloc]\n",
    "        if len(sublabel) == 1:\n",
    "            sublabel = sublabel.upper()\n",
    "        label = latexKeys[\"xbar\"].format(sublabel)\n",
    "    if len(t[1]) == 1:\n",
    "        return '[.{} {}]'.format(label, printTree(t[1]))\n",
    "    return '[.{} \\n\\t{} \\n\\t{}]'.format(label, printTree([t[1][0]]), printTree([t[1][1]]))\n",
    "    \n",
    "print(printTree(treeData[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives the height of a tree, for those from perspective\n",
    "def treeHeight(tree):\n",
    "    if type(tree) == str:\n",
    "        return 0\n",
    "    if len(tree) == 1:\n",
    "        if type(tree[0]) == str:\n",
    "            return 0\n",
    "    return 1+max([treeHeight(_[1]) for _ in tree])\n",
    "    #return max([(0 if len(_) == 1 else max(treeHeight(__) for __ in _[1]) if (type(_) == list) else 0) for _ in tree]) + 1\n",
    "\n",
    "#i = -10\n",
    "#print(final_perspectives[0])#(perspectives[i])\n",
    "#treeHeight(final_perspectives[0])#(perspectives[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for matchLabel, matchSets in matches.items():\n",
    "    for matchSet in matchSets:\n",
    "        print(\"{} :- {}\".format(matchLabel, matchSet))\n",
    "        subset = inp[matchSet[0]:matchSet[1]]\n",
    "        print(inp[:matchSet[0]] + [[matchLabel, subset]] + inp[matchSet[1]:])\n",
    "\n",
    "#subset = inp[matches[matchLabel][0][0]:matches[matchLabel][0][1]]\n",
    "#print(inp[:matches[matchLabel][0][0]] + [[matchLabel, subset]] + inp[matches[matchLabel][0][1]:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ete2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-357cfb3fc2bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mete2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"((a,b),c);\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mytree.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m183\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ete2'"
     ]
    }
   ],
   "source": [
    "from ete2 import Tree\n",
    "t = Tree( \"((a,b),c);\" )\n",
    "t.render(\"mytree.png\", w=183, units=\"mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
