{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is an notebook to research all properties of syntax trees, including:\n",
    "Finding association rules\n",
    "\n",
    "Filling in the blank on missing word classes\n",
    "\n",
    "Building trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "import math\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PyDictionary import PyDictionary\n",
    "\n",
    "_d=PyDictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 'The big man from n loving bagels with n'\n",
    "#'The cat killed the dirty dog in the house because he threw nasty bread by the fire'\n",
    "#\"in the smelly and wholesome and brilliant and bubbly couch\"\n",
    "#\"the brilliant and bubbly and whimsical ball\"\n",
    "p = nltk.parse.api.ParserI\n",
    "_d=PyDictionary()\n",
    "\n",
    "#Array forces ordering\n",
    "syntaxRulesReverse = [\n",
    "    ['(adjconj)+adj', 'adj'], \n",
    "    ['(advP)*adj', 'ajP'], \n",
    "    ['(advP)?adv', 'avP'], \n",
    "    ['PnP', 'pP'],\n",
    "    ['(D)?(ajP)*N(pP)*(CP)?', 'nP'], \n",
    "    ['V(nP)+(pP)*', 'vP'], \n",
    "    ['(Nconj)+N', 'N'],\n",
    "    ['(nPconj)+nP', 'nP'],\n",
    "    ['nPvP', 'tP'],\n",
    "    ['(tPconj)+tP', 'tP']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/mkeays/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Word given is not a valid English Word\n",
      "Error: The Following Error occured: list index out of range\n",
      "Error: The Word given is not a valid English Word\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'DadjNPNVNPN'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_x = x.split()\n",
    "_xd = \"\"\n",
    "for token in _x:\n",
    "    _xd += getClass(token)\n",
    "_xd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........DadjNPNVNPN\n",
      "|\n",
      "DajPNPNVNPN\n",
      "|\n",
      "nPPNVNPN\n",
      "|\n",
      "nPPnPVNPN\n",
      "|\n",
      "nPpPVNPN\n",
      "|\n",
      "nPpPVnPPN\n",
      "|\n",
      "nPpPVnPPnP\n",
      "|\n",
      "nPpPVnPpP\n",
      "|\n",
      "nPpPvP\n",
      "|\n"
     ]
    }
   ],
   "source": [
    "tree = [_xd]\n",
    "diagram = []\n",
    "while needsParsing(tree[-1]):\n",
    "    level = \"\"\n",
    "    dlvl = []\n",
    "    for rule in syntaxRulesReverse:\n",
    "        m = re.search(rule[0], tree[-1])\n",
    "        if m:\n",
    "            level = tree[-1][0:m.start()] + rule[1] + tree[-1][m.end():]\n",
    "            tree += [level]\n",
    "            dlvl += [rule[1], tree[-1][m.start():m.end()], m.start(), m.end()]\n",
    "            diagram += [dlvl]\n",
    "            break\n",
    "    if level == \"\":\n",
    "        break\n",
    "    print('.', end='')\n",
    "[print(_, end='\\n|\\n') for _ in tree];None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PP'"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_search = re.search(tree[-2], syntaxRulesReverse[-1][0])\n",
    "tree[-2][0:_search.start()] + syntaxRulesReverse[-1][1] + tree[-2][_search.end():]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def needsParsing(x):\n",
    "    if x != 'nP' and x != 'tP' and x != 'vP' and x != 'CP' and x!= 'pP':\n",
    "        return True\n",
    "    return False\n",
    "def getClass(x):\n",
    "    wC = 'X'\n",
    "    #Meaning -- regular\n",
    "    word = _d.meaning(x)\n",
    "    if word is not None:\n",
    "        wC = list(word.keys())[0]\n",
    "    \n",
    "    #Meaning -- google\n",
    "    word = _d.googlemeaning(x)\n",
    "    if word is not None:\n",
    "        wC =  word.split(':')[1].split()[0]\n",
    "\n",
    "    if wC.lower() == 'noun' or wC.lower() == 'pronoun':\n",
    "        return 'N'\n",
    "    elif wC.lower() == 'verb':\n",
    "        return 'V'\n",
    "    elif wC.lower() == 'adjective':\n",
    "        return 'adj'\n",
    "    elif wC.lower() == 'adverb':\n",
    "        return 'adv'\n",
    "    elif wC.lower() == 'determiner':\n",
    "        return 'D'\n",
    "    elif wC.lower() == 'preposition':\n",
    "        return 'P'\n",
    "    elif wC.lower() == 'conjunction':\n",
    "        return 'conj'\n",
    "        \n",
    "    return wC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /home/mkeays/anaconda3/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-186-b41352501de9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'you'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-183-450a35623fc2>\u001b[0m in \u001b[0;36mgetClass\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeaning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mwC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m#Meaning -- google\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "getClass('you')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Bar and Array Tree Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'transitive verb'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Getting parts of speach using wordsmyth\n",
    "word = \"cover\"\n",
    "url = \"https://www.wordsmyth.net/?level=3&ent={}\".format(word)\n",
    "s = requests.Session()\n",
    "res = s.get(url, verify = False)\n",
    "soup = BeautifulSoup(res.text, 'html5lib')\n",
    "soup.findAll(\"table\", {\"class\": \"maintable\"})[0].find_all('td', {\"class\": \"data\"})[0].a.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temporary static dict\n",
    "localBank = {'is': 'v',\n",
    "             'need' : 'v',\n",
    "             'needs' : 'v',\n",
    "             'do': 'v',\n",
    "             'does': 'v',\n",
    "             'I' : 'pn',\n",
    "             'a' : 'd',\n",
    "             'the' : 'd',\n",
    "            #homework specific - no working suplementary dict\n",
    "            'well': 'adj',\n",
    "            'plays': 'v'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLikelyClass(word, convert = False):\n",
    "    print(word)\n",
    "    if word in localBank:\n",
    "        return localBank[word]\n",
    "    url = \"https://www.wordsmyth.net/?level=3&ent={}\".format(word)\n",
    "    s = requests.Session()\n",
    "    res = s.get(url, verify = False)\n",
    "    soup = BeautifulSoup(res.text, 'html5lib')\n",
    "    txt = soup.findAll(\"table\", {\"class\": \"maintable\"})[0].find_all('td', {\"class\": \"data\"})[0].a.text\n",
    "    switch = {\n",
    "        'determiner'          :        'd',\n",
    "        'noun'                :        'n',\n",
    "        'pronoun'             :        'pn',\n",
    "        'preposition'         :        'p',\n",
    "        'transitive verb'     :        'v', #vt\n",
    "        'intransitive verb'  :         'v', #vi\n",
    "        'ditransitive verb'  :         'v', #vd\n",
    "        'adjective'           :        'adj',\n",
    "        'adverb'              :        'adv',\n",
    "        'conjunction'         :        'conj',\n",
    "    }\n",
    "    if convert and txt in switch:\n",
    "        localBank[word] = switch[txt]\n",
    "        return switch[txt]\n",
    "    return txt\n",
    "\n",
    "def defineLikelyClass(word, wordClass, force=False):\n",
    "    if word not in localBank or force:\n",
    "        localBank[word] = wordClass\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c217422f5740>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgetLikelyClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\'s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-21422e8e4d66>\u001b[0m in \u001b[0;36mgetLikelyClass\u001b[0;34m(word, convert)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html5lib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtxt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"table\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"maintable\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'td'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"data\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     switch = {\n\u001b[1;32m     11\u001b[0m         \u001b[0;34m'determiner'\u001b[0m          \u001b[0;34m:\u001b[0m        \u001b[0;34m'd'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "getLikelyClass('\\'s', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defineLikelyClass('her', 'd', True)\n",
    "x = 'The coach will be using a new approach'.split()\n",
    "y = 'd n t v v d adj n'.split()\n",
    "for i in range(len(x)):\n",
    "    defineLikelyClass(x[i], y[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "coach\n",
      "will\n",
      "be\n",
      "using\n",
      "a\n",
      "new\n",
      "approach\n",
      "[['d', ['The']], ['n', ['coach']], ['t', ['will']], ['v', ['be']], ['v', ['using']], ['d', ['a']], ['adj', ['new']], ['n', ['approach']]]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The coach will be using a new approach\"\n",
    "\n",
    "#This will build all of the possible base cases for perspective\n",
    "#based on research forensics for each given word\n",
    "def constructPerspective(sentence):\n",
    "    perspective = []\n",
    "    tokens = [[_, getLikelyClass(_.lower(), True)] for _ in sentence.split(\" \")]\n",
    "    for token in tokens:\n",
    "        perspective.append([token[1], [token[0]]])\n",
    "    return perspective\n",
    "x = constructPerspective(sentence)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspectives = [x]\n",
    "#I am Michael, I love Raquel, I eat protien, etc...\n",
    "new_perspectives = []\n",
    "exhaustive_perspectives = []\n",
    "rules = {\n",
    "    \"vP\" : [[\"vbar\"], [\"vP\", \"conj\", \"vP\"]],\n",
    "    \"vbar\" : [[\"vbar\", \"pP\"], [\"vbar\", \"advP\"], [\"advP\", \"vbar\"], [\"vbar\", \"dP\"], [\"v\"], [\"v\", \"dP\"], [\"v\", \"adjP\"], [\"v\", \"vP\"]],\n",
    "    \"adjP\" : [[\"adjbar\"]],\n",
    "    \"adjbar\" : [[\"adj\"], [\"advP\", \"adjbar\"]],\n",
    "    \"advP\" : [[\"advbar\"]],\n",
    "    \"advbar\" : [[\"adv\"], [\"advP\", \"advbar\"]],\n",
    "    \"nbar\": [[\"adjP\", \"nbar\"], [\"nbar\", \"pP\"], [\"n\"], [\"n\", \"pP\"], [\"pn\"]],\n",
    "    \"nP\" : [[\"nbar\"], [\"nP\", \"conj\", \"nP\"]],\n",
    "    \"dbar\" : [[\"d\", \"nP\"], [\"nP\"]],\n",
    "    \"dP\" : [[\"dP\", \"dbar\"], [\"dbar\"], [\"dP\", \"conj\", \"dP\"]],\n",
    "    \"pbar\" : [[\"p\", \"dP\"]],\n",
    "    \"pP\" : [[\"pbar\"]],\n",
    "    \"negbar\" : [[\"neg\", \"vP\"]],\n",
    "    \"negP\" : [[\"negbar\"]],\n",
    "    \"t\" : [[\"v\"]],\n",
    "    \"tbar\" : [[\"vP\"], [\"t\", \"vP\"], [\"t\", \"negP\"]],\n",
    "    \"tP\" : [[\"dP\", \"tbar\"], [\"tP\", \"conj\", \"tP\"]],\n",
    "    \"cbar\" : [[\"c\", \"tP\"], [\"tP\"]],\n",
    "    \"cP\" : [[\"cbar\"], [\"cP\", \"conj\", \"cP\"]]\n",
    "}\n",
    "\n",
    "#Keep track of where matches for each rule occurs, when creating a new node,\n",
    "#select the simplest matches first (adjbar before tbar), and the match that occurs later in the tree\n",
    "mutating = True\n",
    "while mutating:\n",
    "    new_perspectives = []\n",
    "    for inp in perspectives:\n",
    "        matches = {}\n",
    "        for rule, conditionSet in rules.items():    \n",
    "                for conditions in conditionSet:\n",
    "                    conditionMatch, conditionPosition = 0, 0\n",
    "                    #print(rule + \" : \" + str(conditions))\n",
    "                    for i in range(len(inp)):\n",
    "                        node = inp[i]\n",
    "                        if node[0] == conditions[conditionMatch]:\n",
    "                            #print(rule + \", \" + node[0])\n",
    "                            if conditionMatch == 0:\n",
    "                                conditionPosition = i\n",
    "                            conditionMatch += 1\n",
    "                            if conditionMatch == len(conditions):\n",
    "                                if rule in matches:\n",
    "                                    matches[rule] += [(conditionPosition, conditionPosition + conditionMatch)]\n",
    "                                else:\n",
    "                                    matches.update({rule:[(conditionPosition, conditionPosition + conditionMatch)]})\n",
    "                                conditionMatch = 0\n",
    "                        else:\n",
    "                            conditionMatch = 0\n",
    "        #print(\"{} -> {}\".format(inp, matches))\n",
    "        for matchLabel, matchSets in matches.items():\n",
    "            for matchSet in matchSets:\n",
    "                #print(\"{} :- {}\".format(matchLabel, matchSet))\n",
    "                subset = inp[matchSet[0]:matchSet[1]]\n",
    "                new_perspective = inp[:matchSet[0]] + [[matchLabel, subset]] + inp[matchSet[1]:]\n",
    "                if new_perspective not in new_perspectives:\n",
    "                    new_perspectives.append(new_perspective)\n",
    "        for perspective in perspectives:\n",
    "            if perspective not in exhaustive_perspectives:\n",
    "                exhaustive_perspectives.append(perspective)\n",
    "            if inTreeTop(perspective, \"cP\", strict = True) == (True, True) and perspective not in new_perspectives:\n",
    "                new_perspectives.append(perspective)\n",
    "    if perspectives == new_perspectives or len(new_perspectives) == 0:\n",
    "        mutating = False\n",
    "        break\n",
    "    perspectives = new_perspectives.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determines if the given rule is at the top of a given tree\n",
    "#Strict disallows the tree from having different neighbors at the top\n",
    "def inTreeTop(tree, rule, strict = False):\n",
    "    retVal = False\n",
    "    strictVal = True\n",
    "    for topNode in tree:\n",
    "        if topNode[0] == rule:\n",
    "            retVal = True\n",
    "        else:\n",
    "            strictVal = False\n",
    "    if strict:\n",
    "        return (retVal, strictVal)\n",
    "    return retVal\n",
    "def pruneTrees(trees):\n",
    "    pruned = []\n",
    "    for tree in trees:\n",
    "        finishedVal = inTreeTop(tree, \"cP\", strict = True)\n",
    "        if finishedVal[0] and finishedVal[1]:\n",
    "            pruned.append(tree)\n",
    "    return pruned\n",
    "final_perspectives = pruneTrees(perspectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 2\n",
      "13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['cP',\n",
       "  [['cbar',\n",
       "    [['tP',\n",
       "      [['dP',\n",
       "        [['dbar', [['d', ['The']], ['nP', [['nbar', [['n', ['coach']]]]]]]]]],\n",
       "       ['tbar',\n",
       "        [['t', ['will']],\n",
       "         ['vP',\n",
       "          [['vbar',\n",
       "            [['v', ['be']],\n",
       "             ['vP',\n",
       "              [['vbar',\n",
       "                [['vbar', [['v', ['using']]]],\n",
       "                 ['dP',\n",
       "                  [['dbar',\n",
       "                    [['d', ['a']],\n",
       "                     ['nP',\n",
       "                      [['nbar',\n",
       "                        [['adjP', [['adjbar', [['adj', ['new']]]]]],\n",
       "                         ['nbar',\n",
       "                          [['n', ['approach']]]]]]]]]]]]]]]]]]]]]]]]]]]]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Trees: {}\".format(len(final_perspectives)))\n",
    "print(treeHeight(final_perspectives[0]))\n",
    "final_perspectives[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[.CP [.$\\bar{C}$ [.TP \n",
      "\t[.DP [.$\\bar{D}$ [.NP [.$\\bar{N}$ [.pn She ]]]]] \n",
      "\t[.$\\bar{T}$ \n",
      "\t[.T might ] \n",
      "\t[.VP [.$\\bar{V}$ \n",
      "\t[.$\\bar{V}$ [.V play ]] \n",
      "\t[.DP [.$\\bar{D}$ [.NP [.$\\bar{N}$ [.N tomorrow ]]]]]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "latexKeys = {\n",
    "    \"xbar\" : '$\\\\bar{{{}}}$'\n",
    "}\n",
    "\n",
    "def printTree(tree):\n",
    "    if type(tree) == str:\n",
    "        return tree + \" \"\n",
    "    t = tree[0]\n",
    "    if type(t) == str:\n",
    "        return t + \" \"\n",
    "    label = t[0]\n",
    "    if len(label) == 1:\n",
    "        label = label.upper()\n",
    "    ploc = label.find('P')\n",
    "    if ploc > 0:\n",
    "        if len(label[:ploc]) == 1:\n",
    "            label = label.upper()\n",
    "    barloc = label.find('bar')\n",
    "    if barloc > 0:\n",
    "        sublabel = label[:barloc]\n",
    "        if len(sublabel) == 1:\n",
    "            sublabel = sublabel.upper()\n",
    "        label = latexKeys[\"xbar\"].format(sublabel)\n",
    "    if len(t[1]) == 1:\n",
    "        return '[.{} {}]'.format(label, printTree(t[1]))\n",
    "    return '[.{} \\n\\t{} \\n\\t{}]'.format(label, printTree([t[1][0]]), printTree([t[1][1]]))\n",
    "    \n",
    "print(printTree(final_perspectives[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives the height of a tree, for those from perspective\n",
    "def treeHeight(tree):\n",
    "    if type(tree) == str:\n",
    "        return 0\n",
    "    if len(tree) == 1:\n",
    "        if type(tree[0]) == str:\n",
    "            return 0\n",
    "    return 1+max([treeHeight(_[1]) for _ in tree])\n",
    "    #return max([(0 if len(_) == 1 else max(treeHeight(__) for __ in _[1]) if (type(_) == list) else 0) for _ in tree]) + 1\n",
    "\n",
    "#i = -10\n",
    "#print(final_perspectives[0])#(perspectives[i])\n",
    "#treeHeight(final_perspectives[0])#(perspectives[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for matchLabel, matchSets in matches.items():\n",
    "    for matchSet in matchSets:\n",
    "        print(\"{} :- {}\".format(matchLabel, matchSet))\n",
    "        subset = inp[matchSet[0]:matchSet[1]]\n",
    "        print(inp[:matchSet[0]] + [[matchLabel, subset]] + inp[matchSet[1]:])\n",
    "\n",
    "#subset = inp[matches[matchLabel][0][0]:matches[matchLabel][0][1]]\n",
    "#print(inp[:matches[matchLabel][0][0]] + [[matchLabel, subset]] + inp[matches[matchLabel][0][1]:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ete2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-357cfb3fc2bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mete2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTree\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"((a,b),c);\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mytree.png\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m183\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mm\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ete2'"
     ]
    }
   ],
   "source": [
    "from ete2 import Tree\n",
    "t = Tree( \"((a,b),c);\" )\n",
    "t.render(\"mytree.png\", w=183, units=\"mm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
