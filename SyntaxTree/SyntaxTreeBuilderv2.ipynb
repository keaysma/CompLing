{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sytax Tree Builder\n",
    "## Version 2\n",
    "### This is an notebook to research all properties of syntax trees, including:\n",
    "- Finding association rules\n",
    "\n",
    "- Filling in the blank on missing word classes\n",
    "\n",
    "- Building trees\n",
    "\n",
    "### Version 2 will feature:\n",
    "- JSON for all data structures\n",
    "\n",
    "- Proper code decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import re\n",
    "import nltk\n",
    "import math\n",
    "import requests\n",
    "import ast\n",
    "from bs4 import BeautifulSoup\n",
    "from PyDictionary import PyDictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X-Bar and Array Tree Data Structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting parts of speach using wordsmyth, for words with many meanings\n",
    "word = \"glass\"\n",
    "url = \"https://www.wordsmyth.net/?level=3&ent={}\".format(word)\n",
    "cert = './wordsmyth.pem'\n",
    "\n",
    "s = requests.Session()\n",
    "\n",
    "res = s.get(url, verify = False)\n",
    "\n",
    "soup = BeautifulSoup(res.text, 'html5lib')\n",
    "mainlist = soup.findAll(\"dl\", {\"class\": \"mainlist\"})\n",
    "if len(mainlist) == 1:\n",
    "    many_parts_of_speech_title = mainlist[0].findAll(\"dt\", text='parts of speech:')\n",
    "    if len(mainlist) == 1:\n",
    "        many_parts_of_speech = many_parts_of_speech_title[0].findNext(\"dd\")\n",
    "        print([_.text for _ in mpos.findAll(\"a\")])\n",
    "    \n",
    "maintable = soup.findAll(\"table\", {\"class\": \"maintable\"})\n",
    "if len(maintable) == 1:\n",
    "    # There is a single definition for this word\n",
    "    part_of_speach_row = maintable[0].findAll(\"tr\", {\"class\": \"postitle\"})\n",
    "    part_of_speach = part_of_speach_row[0].find_all('td', {\"class\": \"data\"})[0].a.text\n",
    "    print(part_of_speach)\n",
    "\n",
    "foobar = soup.findAll(\"div\", {\"class\": \"list_title\"})\n",
    "if len(foobar) == 1 and foobar[0].text == \"Did you mean this word?\":\n",
    "    print(\"These are suggestions\")\n",
    "# This is a page to pick between multiple definitions\n",
    "wordlist = soup.findAll(\"div\", {\"class\": \"wordlist\"})\n",
    "if len(wordlist) == 1:\n",
    "    ref_links = wordlist[0].table.tbody.findAll(\"a\")\n",
    "    [print(ref['href']) for ref in ref_links]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveDict(d, filename):\n",
    "    sD = str(d)\n",
    "    f = open(filename, 'w')\n",
    "    f.write(sD)\n",
    "    f.close()\n",
    "    \n",
    "def loadDict(filename):\n",
    "    f = open(filename, 'r')\n",
    "    sD = f.read()\n",
    "    f.close()\n",
    "    d = ast.literal_eval(sD)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "localBank = loadDict('local_bank.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "localBank = {k:list(set(v if type(v) == type([]) else [v])) for k,v in localBank.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveDict(localBank, 'local_bank.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetchLikelyClass(word = None, rid_url = None):\n",
    "    url = \"https://www.wordsmyth.net/?level=3&ent={}\".format(word) if word else rid_url\n",
    "    s = requests.Session()\n",
    "    res = s.get(url, verify = False)\n",
    "    \n",
    "    likely_class = None\n",
    "    soup = BeautifulSoup(res.text, 'html5lib')\n",
    "    \n",
    "    # There are multiple parts of speech of the word, and just one definition\n",
    "    '''\n",
    "    mainlist = soup.findAll(\"dl\", {\"class\": \"mainlist\"})\n",
    "    if len(mainlist) == 1:\n",
    "        many_parts_of_speech_title = mainlist[0].findAll(\"dt\", text='parts of speech:')\n",
    "        if len(many_parts_of_speech_title) == 1:\n",
    "            many_parts_of_speech = many_parts_of_speech_title[0].findNext(\"dd\")\n",
    "            return [_.text for _ in mpos.findAll(\"a\")]\n",
    "    '''\n",
    "    \n",
    "    # There is a single definition for this word\n",
    "    maintable = soup.findAll(\"table\", {\"class\": \"maintable\"})\n",
    "    if len(maintable) == 1:\n",
    "        part_of_speach_row = maintable[0].findAll(\"tr\", {\"class\": \"postitle\"})\n",
    "        likely_class = part_of_speach_row[0].find_all('td', {\"class\": \"data\"})[0].a.text\n",
    "        return [likely_class] if word else likely_class\n",
    "   \n",
    "    # Make sure this is not a words suggestion page, if it is return None\n",
    "    foobar = soup.findAll(\"div\", {\"class\": \"list_title\"})\n",
    "    if len(foobar) == 1 and foobar[0].text.strip() == \"Did you mean this word?\":\n",
    "        return None\n",
    "\n",
    "    # This is a page to pick between multiple definitions\n",
    "    wordlist = soup.findAll(\"div\", {\"class\": \"wordlist\"})\n",
    "    if len(wordlist) == 1:\n",
    "        ref_links = wordlist[0].table.tbody.findAll(\"a\")\n",
    "        return [fetchLikelyClass(rid_url = ref['href']) for ref in ref_links]\n",
    "    \n",
    "    # No definition found\n",
    "    return None\n",
    "\n",
    "def getLikelyClass(word, convert = True, save = False):\n",
    "    if word in localBank:\n",
    "        return localBank[word]\n",
    "    \n",
    "    rawClassList = fetchLikelyClass(word)\n",
    "    classList = list(set(rawClassList)) #[item for sublist in rawClassList for item in sublist]\n",
    "    \n",
    "    switch = {\n",
    "        'determiner'          :        'd',\n",
    "        'noun'                :        'n',\n",
    "        'pronoun'             :        'pn',\n",
    "        'preposition'         :        'p',\n",
    "        'verb'                :        'v',\n",
    "        'transitive verb'     :        'v', #vt\n",
    "        'intransitive verb'   :        'v', #vi\n",
    "        'ditransitive verb'   :        'v', #vd\n",
    "        'adjective'           :        'adj',\n",
    "        'adverb'              :        'adv',\n",
    "        'conjunction'         :        'conj',\n",
    "    }\n",
    "    \n",
    "    if convert or save:\n",
    "        classList = [switch[_] for _ in classList]\n",
    "    if save and classList is not None:\n",
    "        localBank[word] = classList\n",
    "    return classList\n",
    "\n",
    "def defineLikelyClass(word, wordClass, force=False):\n",
    "    if word not in localBank or force:\n",
    "        localBank[word] = wordClass\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defineLikelyClass('\\'s', 'd', True)\n",
    "getLikelyClass('\\'s', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['v']\n"
     ]
    }
   ],
   "source": [
    "print(getLikelyClass('catch', save = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For machine gunning words into the local word bank!\n",
    "x = 'The dog is in the house'.split()\n",
    "y = 'd n v p d n'.split()\n",
    "for i in range(len(x)):\n",
    "    defineLikelyClass(x[i], y[i], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sentence = \"The coach will be using a new approach\"\n",
    "'''\n",
    "sentence = \"The tall egg is cold\"\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This will build all of the possible base cases for perspective\n",
    "#based on research forensics for each given word\n",
    "def constructPerspective(tokens, parts_of_speach):\n",
    "    return [{'pos' : parts_of_speach[i], 'words' : [tokens[i]]} for i in range(len(tokens))]\n",
    "\n",
    "def constructPerspectivePermutations(pool, pile = []):\n",
    "    if len(pool) == 0:\n",
    "        return pile\n",
    "    else:\n",
    "        if len(pile) == 0:\n",
    "            return recurse(pool[1:], [[_] for _ in pool[0]])\n",
    "        front_pos = pool[0]\n",
    "        for pool_item in front_pos:\n",
    "            for pile_item in pile:\n",
    "                newpile_item = pile_item + [pool_item]\n",
    "                newpile.append(newpile_item)\n",
    "        return recurse(pool[1:], newpile)\n",
    "    if len(newpile) > 0:\n",
    "        return newpile\n",
    "    return pile\n",
    "\n",
    "def constructBasePerspectives(sentence):\n",
    "    perspectives = []\n",
    "    tokens = sentence.strip().split(\" \")\n",
    "    parts_of_speach = [getLikelyClass(_) for _ in tokens]\n",
    "    permutations = constructPerspectivePermutations(parts_of_speach)\n",
    "    return [constructPerspective(tokens, _) for _ in permutations]\n",
    "\n",
    "x = constructBasePerspectives(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'pos': 'd', 'words': ['The']},\n",
       "  {'pos': 'adj', 'words': ['tall']},\n",
       "  {'pos': 'n', 'words': ['egg']},\n",
       "  {'pos': 'v', 'words': ['is']},\n",
       "  {'pos': 'adj', 'words': ['cold']}],\n",
       " [{'pos': 'd', 'words': ['The']},\n",
       "  {'pos': 'adj', 'words': ['tall']},\n",
       "  {'pos': 'v', 'words': ['egg']},\n",
       "  {'pos': 'v', 'words': ['is']},\n",
       "  {'pos': 'adj', 'words': ['cold']}]]"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I am Michael, I love Raquel, I eat protien, etc...\n",
    "rules = {\n",
    "    \"adjP\" : [[\"adjbar\"]],\n",
    "    \"adjbar\" : [[\"adj\"], [\"advP\", \"adjbar\"]],\n",
    "    \"advP\" : [[\"advbar\"]],\n",
    "    \"advbar\" : [[\"adv\"], [\"advP\", \"advbar\"]],\n",
    "    \"nbar\": [[\"adjP\", \"nbar\"], [\"nbar\", \"pP\"], [\"n\"], [\"n\", \"pP\"], [\"pn\"]],\n",
    "    \"nP\" : [[\"nbar\"], [\"nP\", \"conj\", \"nP\"]],\n",
    "    \"dbar\" : [[\"d\", \"nP\"], [\"nP\"]],\n",
    "    \"dP\" : [[\"dP\", \"dbar\"], [\"dbar\"], [\"dP\", \"conj\", \"dP\"]],\n",
    "    \"pbar\" : [[\"p\", \"dP\"]],\n",
    "    \"pP\" : [[\"pbar\"]],\n",
    "    \"vP\" : [[\"vbar\"], [\"vP\", \"conj\", \"vP\"]],\n",
    "    \"vbar\" : [[\"vbar\", \"pP\"], [\"vbar\", \"advP\"], [\"advP\", \"vbar\"], [\"vbar\", \"dP\"], [\"v\"], [\"v\", \"pP\"], [\"v\", \"dP\"], [\"v\", \"adjP\"], [\"v\", \"vP\"]],\n",
    "    \"negbar\" : [[\"neg\", \"vP\"]],\n",
    "    \"negP\" : [[\"negbar\"]],\n",
    "    \"t\" : [[\"v\"]],\n",
    "    \"tbar\" : [[\"vP\"], [\"t\", \"vP\"], [\"t\", \"negP\"]],\n",
    "    \"tP\" : [[\"dP\", \"tbar\"], [\"tP\", \"conj\", \"tP\"]],\n",
    "    \"cbar\" : [[\"c\", \"tP\"], [\"tP\"]],\n",
    "    \"cP\" : [[\"cbar\"], [\"cP\", \"conj\", \"cP\"]]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#determines if the given rule is at the top of a given tree\n",
    "#Strict disallows the tree from having different neighbors at the top\n",
    "def inTreeTop(tree, rule, strict = False):\n",
    "    retVal = False\n",
    "    strictVal = True\n",
    "    for topNode in tree:\n",
    "        if topNode['pos'] == rule:\n",
    "            retVal = True\n",
    "        else:\n",
    "            strictVal = False\n",
    "    if strict:\n",
    "        return (retVal, strictVal)\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruneTrees(trees):\n",
    "    pruned = []\n",
    "    for tree in trees:\n",
    "        finishedVal = inTreeTop(tree, \"cP\", strict = True)\n",
    "        if finishedVal[0] and finishedVal[1]:\n",
    "            pruned.append(tree)\n",
    "    return pruned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging handling, small but out of the tree builder to keep things clean\n",
    "def dprint(statement, currentLevel, evalLevel, **kwargs):\n",
    "    if currentLevel >= evalLevel or currentLevel == -1:\n",
    "        print(statement, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchRules(perspective = [], verbose = 0):\n",
    "    global rules\n",
    "    \n",
    "    matches = {}\n",
    "    for rule, conditionSet in rules.items():  \n",
    "        dprint(\"rule {}\".format(rule), verbose, 5)\n",
    "        for conditions in conditionSet:\n",
    "            conditionMatch, conditionPosition = 0, 0\n",
    "            dprint(\"\\tcond {}\".format(str(conditions)), verbose, 5, end='')\n",
    "            dprint(\": \", verbose, 6, end='\\n')\n",
    "            for i in range(len(perspective)):\n",
    "                node = perspective[i]\n",
    "                if node['pos'] == conditions[conditionMatch]:\n",
    "                    dprint(\"\\t\\t{} <- {}({})\".format(rule, node['pos'], node['words']), verbose, 6)\n",
    "                    if conditionMatch == 0:\n",
    "                        conditionPosition = i\n",
    "                    conditionMatch += 1\n",
    "                    if conditionMatch == len(conditions):\n",
    "                        dprint(\"\\t\\t\\trule match.\", verbose, 6)\n",
    "                        if rule in matches:\n",
    "                            matches[rule] += [(conditionPosition, conditionPosition + conditionMatch)]\n",
    "                        else:\n",
    "                            matches.update({rule:[(conditionPosition, conditionPosition + conditionMatch)]})\n",
    "                        conditionMatch = 0\n",
    "                else:\n",
    "                    conditionMatch = 0\n",
    "            dprint(\"\", verbose, 5)\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateNewPerspectives(perspective, verbose):\n",
    "    new_perspectives = []\n",
    "    matches = matchRules(perspective, verbose)\n",
    "    dprint(\"Inputs to Matches:\\n {} -> {}\".format(perspective, matches), verbose, 2)\n",
    "\n",
    "    dprint(\"Rule matches: \", verbose, 3)\n",
    "    for matchRule, matchIdxTuples in matches.items():\n",
    "        for match in matchIdxTuples:\n",
    "            dprint(\"{} <- {}\".format(matchRule, match), verbose, 3)\n",
    "            \n",
    "            subset = perspective[match[0]:match[1]]\n",
    "            left, right = perspective[:match[0]], perspective[match[1]:]\n",
    "            dprint(\"{}, {}, {}\".format(left, subset, right), verbose, 4)\n",
    "            new_perspective = left + [{'pos' : matchRule, 'words' : subset}] + right\n",
    "\n",
    "            if new_perspective not in new_perspectives:\n",
    "                new_perspectives.append(new_perspective)\n",
    "                \n",
    "    return new_perspectives\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the big boy itself\n",
    "#The rule above define what the builder will try\n",
    "#As of right now, the builder has a few problems\n",
    "#It refuses to accept verb complements\n",
    "#It does not account for null items\n",
    "#As a result it doesn't yet generate movement\n",
    "#\n",
    "#Verboseness is for debugging purposes, it works in levels\n",
    "#0 - Print nothing, smooth, user experience\n",
    "#1 - Prints things like how many trees are being considered in any one permutation of rules\n",
    "#2 - ...\n",
    "#3 - ...\n",
    "#... - ...\n",
    "#-1 - PRINTS. EVERYTHING. Be careful what you wish for!!!\n",
    "def BuildSyntaxTree(perspectives, maxNode = \"cP\", verbose = 0):\n",
    "    #Keep track of where matches for each rule occurs, when creating a new node,\n",
    "    #select the simplest matches first (adjbar before tbar), and the match that occurs later in the tree\n",
    "    \n",
    "    #This is temporary for now -- in the future we will have multiple perspectives, not just one!\n",
    "    #perspectives = [x]\n",
    "    new_perspectives, final_perspectives = [], []\n",
    "    exhaustive_perspectives = perspectives.copy()\n",
    "    \n",
    "    #Measures tree formation\n",
    "    while True:\n",
    "        new_perspectives = []\n",
    "        for perspective in perspectives:\n",
    "            new_perspectives += generateNewPerspectives(perspective, verbose)\n",
    "        dprint(\"new perspectives: {}\".format(new_perspectives), verbose, 4)\n",
    "        \n",
    "        dprint(\"Filling in Exaustive and Final arrays...\", verbose, 2)\n",
    "        next_perspectives = []\n",
    "        for perspective in new_perspectives:\n",
    "            if perspective not in exhaustive_perspectives:\n",
    "                dprint(\"{} -> exhaustive_perspectives, generically missing\".format(perspective), verbose, 3)\n",
    "                exhaustive_perspectives.append(perspective)\n",
    "                next_perspectives.append(perspective)\n",
    "            if inTreeTop(perspective, maxNode, strict = True) == (True, True) and perspective not in final_perspectives:\n",
    "                dprint(\"{} -> final_perspectives, completed tree\".format(perspective), verbose, 3)\n",
    "                final_perspectives.append(perspective)\n",
    "        \n",
    "        #Stops searching\n",
    "        if perspectives == next_perspectives or len(next_perspectives) == 0:\n",
    "            dprint(\"Halting, onboarding last trees\", verbose, 2)\n",
    "            for perspective in next_perspectives:\n",
    "                if perspective not in final_perspectives:\n",
    "                    dprint(\"{} -> final_perspectives\".format(perspective), verbose, 3)\n",
    "                    final_perspectives.append(perspectives)\n",
    "            dprint(\"Halted\", verbose, 0)\n",
    "            break\n",
    "        perspectives = next_perspectives.copy()\n",
    "        dprint(\"New perspectives: {}\\tTotal: {}\".format(len(perspectives), len(exhaustive_perspectives)), verbose, 1)\n",
    "    #Returns a tuple of:\n",
    "    #Final list of highest level trees\n",
    "    #All generated trees\n",
    "    #Changes, corresponding to exhaustive indicies\n",
    "    return (final_perspectives, exhaustive_perspectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tall egg is cold\n",
      "Halted\n"
     ]
    }
   ],
   "source": [
    "print(sentence)\n",
    "p = constructBasePerspectives(sentence)\n",
    "treeData = BuildSyntaxTree(p, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'pos': 'cP',\n",
       "  'words': [{'pos': 'cbar',\n",
       "    'words': [{'pos': 'tP',\n",
       "      'words': [{'pos': 'dP',\n",
       "        'words': [{'pos': 'dbar',\n",
       "          'words': [{'pos': 'd', 'words': 'The'},\n",
       "           {'pos': 'nP',\n",
       "            'words': [{'pos': 'nbar',\n",
       "              'words': [{'pos': 'adjP',\n",
       "                'words': [{'pos': 'adjbar',\n",
       "                  'words': [{'pos': 'adj', 'words': 'tall'}]}]},\n",
       "               {'pos': 'nbar',\n",
       "                'words': [{'pos': 'n', 'words': 'egg'}]}]}]}]}]},\n",
       "       {'pos': 'tbar',\n",
       "        'words': [{'pos': 'vP',\n",
       "          'words': [{'pos': 'vbar',\n",
       "            'words': [{'pos': 'v', 'words': 'is'},\n",
       "             {'pos': 'adjP',\n",
       "              'words': [{'pos': 'adjbar',\n",
       "                'words': [{'pos': 'adj', 'words': 'cold'}]}]}]}]}]}]}]}]}]"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalTree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalTree = pruneTrees(treeData[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gives the height of a tree, for those from perspective\n",
    "def treeHeight(tree):\n",
    "    if type(tree) == str:\n",
    "        return 0\n",
    "    if len(tree) == 0:\n",
    "        return 0\n",
    "    if len(tree) == 1:\n",
    "        if type(tree[0]) == str:\n",
    "            return 0\n",
    "    return 1+max([treeHeight(_['words']) for _ in tree])\n",
    "    #return max([(0 if len(_) == 1 else max(treeHeight(__) for __ in _[1]) if (type(_) == list) else 0) for _ in tree]) + 1\n",
    "\n",
    "#i = -10\n",
    "#print(final_perspectives[0])#(perspectives[i])\n",
    "#treeHeight(final_perspectives[0])#(perspectives[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trees: 1\n",
      "10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'pos': 'cP',\n",
       "  'words': [{'pos': 'cbar',\n",
       "    'words': [{'pos': 'tP',\n",
       "      'words': [{'pos': 'dP',\n",
       "        'words': [{'pos': 'dbar',\n",
       "          'words': [{'pos': 'd', 'words': ['The']},\n",
       "           {'pos': 'nP',\n",
       "            'words': [{'pos': 'nbar',\n",
       "              'words': [{'pos': 'adjP',\n",
       "                'words': [{'pos': 'adjbar',\n",
       "                  'words': [{'pos': 'adj', 'words': ['tall']}]}]},\n",
       "               {'pos': 'nbar',\n",
       "                'words': [{'pos': 'n', 'words': ['egg']}]}]}]}]}]},\n",
       "       {'pos': 'tbar',\n",
       "        'words': [{'pos': 'vP',\n",
       "          'words': [{'pos': 'vbar',\n",
       "            'words': [{'pos': 'v', 'words': ['is']},\n",
       "             {'pos': 'adjP',\n",
       "              'words': [{'pos': 'adjbar',\n",
       "                'words': [{'pos': 'adj', 'words': ['cold']}]}]}]}]}]}]}]}]}]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Trees: {}\".format(len(finalTree)))\n",
    "print(treeHeight(finalTree[0]))\n",
    "finalTree[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[.CP [.$\\bar{C}$ [.TP \n",
      "   [.DP [.$\\bar{D}$ \n",
      "     [.D The ] \n",
      "     [.NP [.$\\bar{N}$ \n",
      "       [.adjP [.$\\bar{adj}$ [.adj tall ]]] \n",
      "       [.$\\bar{N}$ [.N egg ]]]]]] \n",
      "   [.$\\bar{T}$ [.VP [.$\\bar{V}$ \n",
      "      [.V is ] \n",
      "      [.adjP [.$\\bar{adj}$ [.adj cold ]]]]]]]]]\n"
     ]
    }
   ],
   "source": [
    "latexKeys = {\n",
    "    \"xbar\" : '$\\\\bar{{{}}}$'\n",
    "}\n",
    "\n",
    "def latexTree(tree, depth = 1):\n",
    "    if type(tree) == str:\n",
    "        return tree + \" \"\n",
    "    if type(tree) == type([]):\n",
    "        t = tree[0]\n",
    "        if type(t) == str:\n",
    "            return t + \" \"\n",
    "    label = t['pos']\n",
    "    if len(label) == 1:\n",
    "        label = label.upper()\n",
    "    ploc = label.find('P')\n",
    "    if ploc > 0:\n",
    "        if len(label[:ploc]) == 1:\n",
    "            label = label.upper()\n",
    "    barloc = label.find('bar')\n",
    "    if barloc > 0:\n",
    "        sublabel = label[:barloc]\n",
    "        if len(sublabel) == 1:\n",
    "            sublabel = sublabel.upper()\n",
    "        label = latexKeys[\"xbar\"].format(sublabel)\n",
    "    if len(t['words']) == 1:\n",
    "        return '[.{} {}]'.format(label, latexTree(t['words'], depth+1))\n",
    "    return '[.{} \\n{}{} \\n{}{}]'.format(label, ' '*depth, latexTree([t['words'][0]], depth+1), ' '*depth, latexTree([t['words'][1]], depth+1))\n",
    "    \n",
    "print(latexTree(treeData[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(cP,((cbar,((tP,((dP,((dbar,((D,(The )),(nP,((nbar,((adjP,((adjbar,((adj,(tall )))))),(nbar,((N,(egg )))))))))))),(tbar,((vP,((vbar,((V,(is )),(adjP,((adjbar,((adj,(cold ))))))))))))))))))\n"
     ]
    }
   ],
   "source": [
    "def eteTree(tree, depth = 1):\n",
    "    if type(tree) == str:\n",
    "        return tree + \" \"\n",
    "    if type(tree) == type([]):\n",
    "        t = tree[0]\n",
    "        if type(t) == str:\n",
    "            return t + \" \"\n",
    "    label = t['pos']\n",
    "    if len(label) == 1:\n",
    "        label = label.upper()\n",
    "    #ploc = label.find('P')\n",
    "    #if ploc > 0:\n",
    "    #    if len(label[:ploc]) == 1:\n",
    "    #        label = label.upper()\n",
    "    #barloc = label.find('bar')\n",
    "    #if barloc > 0:\n",
    "    #    sublabel = label[:barloc]\n",
    "    #    if len(sublabel) == 1:\n",
    "    #        sublabel = sublabel.upper()\n",
    "    #    label = latexKeys[\"xbar\"].format(sublabel)\n",
    "    if len(t['words']) == 1:\n",
    "        return '({},({}))'.format(label, eteTree(t['words'], depth+1))\n",
    "    return '({},({},{}))'.format(label, eteTree([t['words'][0]], depth+1), eteTree([t['words'][1]], depth+1))\n",
    "    \n",
    "print(eteTree(treeData[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nodes': [[127.0, 0.5, 131.0, 4.5, 0, None],\n",
       "  [127.0, 123.5, 131.0, 127.5, 1, None],\n",
       "  [127.0, 246.5, 131.0, 250.5, 2, None]],\n",
       " 'faces': [[121.5, 250.0, 136.5, 259.0, 2, 'a']],\n",
       " 'node_areas': {0: [121.5, 1.0, 136.5, 259.0],\n",
       "  1: [121.5, 4.0, 136.5, 259.0],\n",
       "  2: [121.5, 127.0, 136.5, 259.0]}}"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ete3 import Tree, TreeStyle\n",
    "#t = Tree( \"{};\".format(eteTree(treeData[0][0])) )\n",
    "ts = TreeStyle()\n",
    "ts.show_leaf_name = True\n",
    "ts.rotation = 90\n",
    "ts.scale = 120\n",
    "t.render(\"etetree.png\", tree_style=ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anyTree(tree, parent = None):\n",
    "    if parent is None and len(tree) == 1:\n",
    "        root = Node(tree[0]['pos'])\n",
    "        anyTree(tree[0]['words'], root)\n",
    "        return root\n",
    "    for child in tree:\n",
    "        if type(child) is dict:\n",
    "            node = Node(child['pos'], parent = parent)\n",
    "            anyTree(child['words'], node)\n",
    "        if type(child) is str:\n",
    "            node = Node(child, parent = parent)\n",
    "    return None\n",
    "    \n",
    "anyTreeRoot = anyTree(treeData[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pos': 'cbar',\n",
       " 'words': [{'pos': 'tP',\n",
       "   'words': [{'pos': 'dP',\n",
       "     'words': [{'pos': 'dbar',\n",
       "       'words': [{'pos': 'd', 'words': ['The']},\n",
       "        {'pos': 'nP',\n",
       "         'words': [{'pos': 'nbar',\n",
       "           'words': [{'pos': 'adjP',\n",
       "             'words': [{'pos': 'adjbar',\n",
       "               'words': [{'pos': 'adj', 'words': ['tall']}]}]},\n",
       "            {'pos': 'nbar', 'words': [{'pos': 'n', 'words': ['egg']}]}]}]}]}]},\n",
       "    {'pos': 'tbar',\n",
       "     'words': [{'pos': 'vP',\n",
       "       'words': [{'pos': 'vbar',\n",
       "         'words': [{'pos': 'v', 'words': ['is']},\n",
       "          {'pos': 'adjP',\n",
       "           'words': [{'pos': 'adjbar',\n",
       "             'words': [{'pos': 'adj', 'words': ['cold']}]}]}]}]}]}]}]}"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "treeData[0][0][0]['words'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cP\n",
      "└── cbar\n",
      "    └── tP\n",
      "        ├── dP\n",
      "        │   └── dbar\n",
      "        │       ├── d\n",
      "        │       │   └── The\n",
      "        │       └── nP\n",
      "        │           └── nbar\n",
      "        │               └── n\n",
      "        │                   └── chicken\n",
      "        └── tbar\n",
      "            └── vP\n",
      "                └── vbar\n",
      "                    └── v\n",
      "                        └── ran\n"
     ]
    }
   ],
   "source": [
    "for pre, fill, node in RenderTree(anyTreeRoot):\n",
    "    print(\"%s%s\" % (pre, node.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "from anytree.exporter import UniqueDotExporter\n",
    "#sudo apt install graphviz\n",
    "def graphAnyTree(anyTreeRoot, filename):\n",
    "    def nodenamefunc(node):\n",
    "        return '%s' % (node.name)\n",
    "\n",
    "    UniqueDotExporter(anyTreeRoot, \n",
    "                      nodenamefunc=nodenamefunc,\n",
    "                      nodeattrfunc=lambda node: \"shape=none\").to_picture(\"{}.png\".format(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph tree {\n",
      "    \"0x7f40717d6208\" [label=\"test\"];\n",
      "    \"0x7f40717d6240\" [label=\"test2\"];\n",
      "    \"0x7f40717d62b0\" [label=\"test3\"];\n",
      "    \"0x7f40717d6208\" -> \"0x7f40717d6240\";\n",
      "    \"0x7f40717d6208\" -> \"0x7f40717d62b0\";\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "root = Node(\"test\",display_name=\"test\")\n",
    "node = Node(\"test2\", parent = root, display_name=\"test2\")\n",
    "node2 = Node(\"test3\", parent = root, display_name=\"test2\")\n",
    "for line in UniqueDotExporter(root):  # doctest: +SKIP\n",
    "    print(line)\n",
    "UniqueDotExporter(root, \n",
    "                      nodenamefunc=nodenamefunc,\n",
    "                      nodeattrfunc=lambda node: 'label=\"{}\";shape=none'.format(node.display_name)).to_picture(\"{}.png\".format(\"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Node' object has no attribute 'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-398-d0d511a1001c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mroot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Node' object has no attribute 'id'"
     ]
    }
   ],
   "source": [
    "root.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n",
      "/home/mkeays/anaconda3/lib/python3.6/site-packages/urllib3/connectionpool.py:857: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Halted\n"
     ]
    }
   ],
   "source": [
    "#A whole test from top to bottom\n",
    "sentence = \"The chicken ran\"\n",
    "p = constructBasePerspectives(sentence)\n",
    "treeData = BuildSyntaxTree(p, verbose = 0)\n",
    "finalTrees = pruneTrees(treeData[0])\n",
    "anyTreeRoot = anyTree(finalTrees[0])\n",
    "graphAnyTree(anyTreeRoot, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
